"""
DeepSeek-OCR Microservice - vLLM + FastAPI

HTTP API –¥–ª—è OCR –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º DeepSeek-OCR –º–æ–¥–µ–ª–∏.

Endpoints:
- POST /ocr/page - OCR –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
- POST /ocr/figure - OCR –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
- GET /health - –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞

–ò—Å–ø–æ–ª—å–∑—É–µ—Ç vLLM –¥–ª—è inference —Å custom NGramPerReqLogitsProcessor.
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional, List, Dict, Any
import base64
import io
from PIL import Image
import uuid

# vLLM imports (–±—É–¥—É—Ç –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏ —Å vLLM)
try:
    from vllm import LLM, SamplingParams
    from vllm.sampling_params import LogitsProcessor
    VLLM_AVAILABLE = True
except ImportError:
    VLLM_AVAILABLE = False
    print("‚ö†Ô∏è  vLLM –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ú–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ stub-—Ä–µ–∂–∏–º–µ.")


# ============================================================================
# Pydantic Models
# ============================================================================

class OCRRequest(BaseModel):
    """–ó–∞–ø—Ä–æ—Å –Ω–∞ OCR"""
    image: str  # base64 encoded image
    mode: str = "Base"  # Tiny, Small, Base, Large, Gundam
    prompt: str = "Convert the entire page/image into Markdown format."
    page_id: int = 0
    bbox: Optional[List[float]] = None


class OCRBlockResponse(BaseModel):
    """–ë–ª–æ–∫ –≤ –æ—Ç–≤–µ—Ç–µ OCR"""
    id: str
    type: str
    content: str
    bbox: List[float]
    confidence: float
    metadata: Dict[str, Any] = {}


class OCRResponse(BaseModel):
    """–û—Ç–≤–µ—Ç –æ—Ç OCR"""
    markdown: str
    blocks: List[OCRBlockResponse]
    page_id: int
    vision_tokens: int
    text_tokens: int
    mode: str


# ============================================================================
# FastAPI App
# ============================================================================

app = FastAPI(
    title="DeepSeek-OCR Microservice",
    description="OCR —Å–µ—Ä–≤–∏—Å –Ω–∞ –±–∞–∑–µ vLLM + DeepSeek-OCR",
    version="0.1.0"
)


# ============================================================================
# DeepSeek-OCR Engine
# ============================================================================

class DeepSeekOCREngine:
    """
    –î–≤–∏–∂–æ–∫ –¥–ª—è DeepSeek-OCR –Ω–∞ –±–∞–∑–µ vLLM
    
    –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å DeepSeek-OCR –∏ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∑–∞–ø—Ä–æ—Å—ã.
    """
    
    # Vision tokens –ø–æ —Ä–µ–∂–∏–º–∞–º (–∏–∑ DeepSeek-OCR README)
    MODE_TOKENS = {
        "Tiny": 64,
        "Small": 100,
        "Base": 256,
        "Large": 400,
        "Gundam": None  # Dynamic
    }
    
    def __init__(self, model_path: str = "deepseek-ai/deepseek-ocr"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–≤–∏–∂–∫–∞
        
        Args:
            model_path: –ü—É—Ç—å –∫ –º–æ–¥–µ–ª–∏ DeepSeek-OCR
        """
        self.model_path = model_path
        self.llm = None
        
        if VLLM_AVAILABLE:
            self._load_model()
        else:
            print("‚ö†Ô∏è  Stub —Ä–µ–∂–∏–º: OCR –±—É–¥–µ—Ç –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å –∑–∞–≥–ª—É—à–∫–∏")
    
    def _load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —á–µ—Ä–µ–∑ vLLM"""
        try:
            print(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏: {self.model_path}")
            
            self.llm = LLM(
                model=self.model_path,
                trust_remote_code=True,  # –¢—Ä–µ–±—É–µ—Ç—Å—è –¥–ª—è DeepSeek-OCR
                gpu_memory_utilization=0.9,
                max_model_len=4096,
            )
            
            print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            raise
    
    def process_image(self, image_bytes: bytes, mode: str, prompt: str) -> Dict[str, Any]:
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ OCR
        
        Args:
            image_bytes: –ë–∞–π—Ç—ã –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            mode: –†–µ–∂–∏–º OCR (Tiny/Small/Base/Large/Gundam)
            prompt: –ü—Ä–æ–º–ø—Ç –¥–ª—è –º–æ–¥–µ–ª–∏
        
        Returns:
            Dict —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ OCR
        """
        if not VLLM_AVAILABLE or not self.llm:
            # Stub —Ä–µ–∂–∏–º
            return self._stub_ocr(image_bytes, mode)
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = Image.open(io.BytesIO(image_bytes))
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º inputs –¥–ª—è vLLM
            # (—Ç–æ—á–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–∞–≤–∏—Å–∏—Ç –æ—Ç —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ DeepSeek-OCR)
            
            # Sampling parameters —Å custom logits processor
            sampling_params = SamplingParams(
                temperature=0.0,  # –î–µ—Ç–µ—Ä–º–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ –¥–ª—è OCR
                max_tokens=2048,  # –ú–∞–∫—Å–∏–º—É–º —Ç–æ–∫–µ–Ω–æ–≤ –¥–ª—è –≤—ã–≤–æ–¥–∞
                # logits_processors=[NGramPerReqLogitsProcessor(...)],  # –ï—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
            )
            
            # Inference
            outputs = self.llm.generate(
                prompts=[prompt],
                sampling_params=sampling_params,
                # image=image,  # –ü–µ—Ä–µ–¥–∞—á–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (API vLLM)
            )
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            generated_text = outputs[0].outputs[0].text
            
            # –ü–∞—Ä—Å–∏–º Markdown –∏ —Å–æ–∑–¥–∞–µ–º –±–ª–æ–∫–∏
            blocks = self._parse_markdown_to_blocks(generated_text)
            
            # –ü–æ–¥—Å—á–µ—Ç —Ç–æ–∫–µ–Ω–æ–≤
            vision_tokens = self.MODE_TOKENS.get(mode, 256)
            text_tokens = len(outputs[0].outputs[0].token_ids)
            
            return {
                "markdown": generated_text,
                "blocks": blocks,
                "vision_tokens": vision_tokens,
                "text_tokens": text_tokens,
                "mode": mode
            }
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ OCR: {e}")
            raise
    
    def _stub_ocr(self, image_bytes: bytes, mode: str) -> Dict[str, Any]:
        """
        –ó–∞–≥–ª—É—à–∫–∞ –¥–ª—è OCR (–∫–æ–≥–¥–∞ vLLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω)
        
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –≤–∞–ª–∏–¥–Ω—ã–π –æ—Ç–≤–µ—Ç –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è.
        """
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        image = Image.open(io.BytesIO(image_bytes))
        width, height = image.size
        
        stub_markdown = f"""# Stub OCR Result

This is a stub response (vLLM not available).

Image size: {width}x{height}
Mode: {mode}

**Note:** This is placeholder text. Deploy vLLM with DeepSeek-OCR for actual OCR.
"""
        
        blocks = [
            {
                "id": f"stub_{uuid.uuid4().hex[:8]}",
                "type": "paragraph",
                "content": "Stub OCR content",
                "bbox": [0, 0, float(width), float(height)],
                "confidence": 1.0,
                "metadata": {"stub": True}
            }
        ]
        
        return {
            "markdown": stub_markdown,
            "blocks": blocks,
            "vision_tokens": self.MODE_TOKENS.get(mode, 256),
            "text_tokens": len(stub_markdown.split()),
            "mode": mode
        }
    
    def _parse_markdown_to_blocks(self, markdown: str) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ Markdown –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –±–ª–æ–∫–∏
        
        –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–∞–∑–±–∏–µ–Ω–∏—è –Ω–∞ –±–ª–æ–∫–∏.
        –î–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å markdown parser.
        
        Args:
            markdown: Markdown —Ç–µ–∫—Å—Ç
        
        Returns:
            –°–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤
        """
        blocks = []
        lines = markdown.split('\n')
        
        block_counter = 0
        for line in lines:
            if not line.strip():
                continue
            
            block_counter += 1
            block_id = f"block_{block_counter}_{uuid.uuid4().hex[:8]}"
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –±–ª–æ–∫–∞
            if line.startswith('#'):
                block_type = "heading"
            elif line.startswith('- ') or line.startswith('* '):
                block_type = "list"
            elif line.startswith('|'):
                block_type = "table"
            else:
                block_type = "paragraph"
            
            blocks.append({
                "id": block_id,
                "type": block_type,
                "content": line,
                "bbox": [0, 0, 0, 0],  # TODO: Extract from OCR if available
                "confidence": 0.95,
                "metadata": {}
            })
        
        return blocks


# ============================================================================
# Global Engine Instance
# ============================================================================

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –¥–≤–∏–∂–æ–∫ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
ocr_engine = None

@app.on_event("startup")
async def startup_event():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ —Å–µ—Ä–≤–∏—Å–∞"""
    global ocr_engine
    
    # TODO: –ü–æ–ª—É—á–∏—Ç—å model_path –∏–∑ environment variables
    model_path = "deepseek-ai/deepseek-ocr"
    
    try:
        ocr_engine = DeepSeekOCREngine(model_path=model_path)
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")
        print("‚ö†Ô∏è  –°–µ—Ä–≤–∏—Å –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –≤ stub-—Ä–µ–∂–∏–º–µ")
        ocr_engine = DeepSeekOCREngine(model_path="stub")


# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è —Å–µ—Ä–≤–∏—Å–∞"""
    return {
        "status": "healthy",
        "vllm_available": VLLM_AVAILABLE,
        "model_loaded": ocr_engine is not None and ocr_engine.llm is not None
    }


@app.post("/ocr/page", response_model=OCRResponse)
async def ocr_page(request: OCRRequest):
    """
    OCR –≤—Å–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã PDF
    
    Args:
        request: OCRRequest —Å base64 –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º
    
    Returns:
        OCRResponse —Å Markdown –∏ –±–ª–æ–∫–∞–º–∏
    """
    if not ocr_engine:
        raise HTTPException(status_code=503, detail="OCR engine not initialized")
    
    try:
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º base64
        image_bytes = base64.b64decode(request.image)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–µ—Ä–µ–∑ OCR
        result = ocr_engine.process_image(
            image_bytes=image_bytes,
            mode=request.mode,
            prompt=request.prompt
        )
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        return OCRResponse(
            markdown=result["markdown"],
            blocks=[OCRBlockResponse(**b) for b in result["blocks"]],
            page_id=request.page_id,
            vision_tokens=result["vision_tokens"],
            text_tokens=result["text_tokens"],
            mode=result["mode"]
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OCR processing error: {str(e)}")


@app.post("/ocr/figure", response_model=OCRResponse)
async def ocr_figure(request: OCRRequest):
    """
    OCR –æ—Ç–¥–µ–ª—å–Ω–æ–π —Ñ–∏–≥—É—Ä—ã/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    
    –ê–Ω–∞–ª–æ–≥–∏—á–µ–Ω /ocr/page, –Ω–æ —Å –¥—Ä—É–≥–∏–º –¥–µ—Ñ–æ–ª—Ç–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º.
    """
    if not ocr_engine:
        raise HTTPException(status_code=503, detail="OCR engine not initialized")
    
    try:
        image_bytes = base64.b64decode(request.image)
        
        result = ocr_engine.process_image(
            image_bytes=image_bytes,
            mode=request.mode,
            prompt=request.prompt
        )
        
        return OCRResponse(
            markdown=result["markdown"],
            blocks=[OCRBlockResponse(**b) for b in result["blocks"]],
            page_id=request.page_id,
            vision_tokens=result["vision_tokens"],
            text_tokens=result["text_tokens"],
            mode=result["mode"]
        )
    
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"OCR processing error: {str(e)}")


# ============================================================================
# Main (–¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞)
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info"
    )

