# –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—é DeepSeek-OCR

–ü–æ–ª–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ —É—Å—Ç–∞–Ω–æ–≤–∫–µ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–µ DeepSeek-OCR –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞ BPMN Process Automation –Ω–∞ WSL2 Ubuntu.

---

## üìã –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ

- [–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∏—Å—Ç–µ–º–µ](#—Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è-–∫-—Å–∏—Å—Ç–µ–º–µ)
- [–ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è](#–ø—Ä–æ–≤–µ—Ä–∫–∞-–æ–∫—Ä—É–∂–µ–Ω–∏—è)
- [–£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ WSL2 Ubuntu](#—É—Å—Ç–∞–Ω–æ–≤–∫–∞-–Ω–∞-wsl2-ubuntu)
- [–ù–∞—Å—Ç—Ä–æ–π–∫–∞ DeepSeek-OCR](#–Ω–∞—Å—Ç—Ä–æ–π–∫–∞-deepseek-ocr)
- [–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–æ–µ–∫—Ç–æ–º](#–∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è-—Å-–ø—Ä–æ–µ–∫—Ç–æ–º)
- [–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏](#–ø—Ä–æ–≤–µ—Ä–∫–∞-—Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏)
- [–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º](#—Ä–µ—à–µ–Ω–∏–µ-–ø—Ä–æ–±–ª–µ–º)

---

## üñ•Ô∏è –¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ —Å–∏—Å—Ç–µ–º–µ

### –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **OS**: Windows 10/11 —Å WSL2
- **GPU**: NVIDIA —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA (–º–∏–Ω–∏–º—É–º 8GB VRAM)
- **RAM**: 16GB+ —Å–∏—Å—Ç–µ–º–Ω–æ–π –ø–∞–º—è—Ç–∏
- **–î–∏—Å–∫**: 30GB+ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞
- **CUDA**: 11.5+ (–¥—Ä–∞–π–≤–µ—Ä NVIDIA)

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è

- **GPU**: NVIDIA RTX 4090, RTX 5080 –∏–ª–∏ –ª—É—á—à–µ (16GB+ VRAM)
- **RAM**: 32GB+ —Å–∏—Å—Ç–µ–º–Ω–æ–π –ø–∞–º—è—Ç–∏
- **–î–∏—Å–∫**: 50GB+ —Å–≤–æ–±–æ–¥–Ω–æ–≥–æ –º–µ—Å—Ç–∞ (SSD)
- **CUDA**: 12.1+

---

## üîç –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

### –®–∞–≥ 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ WSL2

```powershell
# –í PowerShell –ø—Ä–æ–≤–µ—Ä—è–µ–º —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ª–∏ WSL2
wsl --list --verbose
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
  NAME                   STATE           VERSION
* Ubuntu-22.04           Running         2
  docker-desktop         Stopped         2
```

–ï—Å–ª–∏ WSL2 –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
```powershell
wsl --install -d Ubuntu-22.04
```

### –®–∞–≥ 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ NVIDIA GPU

```bash
# –í WSL Ubuntu
nvidia-smi
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 575.64.01              Driver Version: 576.88         CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
|   0  NVIDIA GeForce RTX 5080        On  |   00000000:01:00.0  On |                  N/A |
+-----------------------------------------------------------------------------------------+
```

–ï—Å–ª–∏ `nvidia-smi` –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç - —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ NVIDIA CUDA Toolkit –¥–ª—è WSL2:
- –°–∫–∞—á–∞–π—Ç–µ —Å: https://developer.nvidia.com/cuda-downloads
- –í—ã–±–µ—Ä–∏—Ç–µ: Linux ‚Üí x86_64 ‚Üí WSL-Ubuntu ‚Üí 2.0 ‚Üí deb (network)

### –®–∞–≥ 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ CUDA Toolkit

```bash
# –í WSL Ubuntu
nvcc --version
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
Cuda compilation tools, release 11.5, V11.5.119
```

–ï—Å–ª–∏ CUDA toolkit –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ CUDA Toolkit 12.x
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
sudo dpkg -i cuda-keyring_1.1-1_all.deb
sudo apt-get update
sudo apt-get -y install cuda-toolkit-12-8
```

### –®–∞–≥ 4: –ü—Ä–æ–≤–µ—Ä–∫–∞ Python

```bash
# –í WSL Ubuntu
python3 --version
```

**–¢—Ä–µ–±—É–µ—Ç—Å—è**: Python 3.10 –∏–ª–∏ 3.11

–ï—Å–ª–∏ Python –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω:
```bash
sudo apt update
sudo apt install -y python3 python3-pip python3-venv
```

---

## üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ WSL2 Ubuntu

### –®–∞–≥ 1: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞

```bash
# –ü–µ—Ä–µ—Ö–æ–¥ –≤ Windows –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —á–µ—Ä–µ–∑ WSL
cd /mnt/c/Users/YOUR_USERNAME/Obligations

# –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (–µ—Å–ª–∏ –µ—â–µ –Ω–µ —Å–¥–µ–ª–∞–Ω–æ)
git clone YOUR_REPO_URL
cd Obligations
```

### –®–∞–≥ 2: –ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ DeepSeek-OCR

```bash
# –í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –ø—Ä–æ–µ–∫—Ç–∞
git clone https://github.com/deepseek-ai/DeepSeek-OCR.git
cd DeepSeek-OCR
```

### –®–∞–≥ 3: –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏—Ä—Ç—É–∞–ª—å–Ω–æ–≥–æ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
# –°–æ–∑–¥–∞–Ω–∏–µ venv
python3 -m venv venv

# –ê–∫—Ç–∏–≤–∞—Ü–∏—è
source venv/bin/activate

# –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ pip
pip install --upgrade pip
```

### –®–∞–≥ 4: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch —Å CUDA

**–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û –¥–ª—è RTX 5080 (Blackwell, sm_120)!**

```bash
# PyTorch 2.9.0 + CUDA 12.8 (~2.5GB, 5-10 –º–∏–Ω—É—Ç)
# –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –¥–ª—è RTX 5080! –ë–æ–ª–µ–µ —Å—Ç–∞—Ä—ã–µ –≤–µ—Ä—Å–∏–∏ –ù–ï –†–ê–ë–û–¢–ê–Æ–¢!
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch:**
```bash
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'CUDA Version: {torch.version.cuda}'); print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')"
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
PyTorch: 2.9.0+cu128
CUDA Available: True
CUDA Version: 12.8
GPU: NVIDIA GeForce RTX 5080
```

**–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã:**
- PyTorch 2.9.0 –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç: sm_50, sm_60, sm_70, sm_75, sm_80, sm_86, sm_90, **sm_120 (Blackwell)**
- PyTorch 2.7.x –∏ —Å—Ç–∞—Ä—à–µ: **–ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç sm_120** ‚Üí RTX 5080 –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç!

### –®–∞–≥ 5: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π DeepSeek-OCR

```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ requirements.txt (~2GB, 2-3 –º–∏–Ω—É—Ç—ã)
pip install -r requirements.txt
```

**requirements.txt –≤–∫–ª—é—á–∞–µ—Ç:**
- transformers==4.46.3
- tokenizers==0.20.3
- PyMuPDF
- img2pdf
- einops
- easydict
- addict
- Pillow
- numpy

### –®–∞–≥ 6: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ vLLM

```bash
# vLLM –¥–ª—è high-performance inference (~2GB, 5-7 –º–∏–Ω—É—Ç)
pip install vllm
```

**–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞**: –ï—Å–ª–∏ –≤–æ–∑–Ω–∏–∫–∞—é—Ç –ø—Ä–æ–±–ª–µ–º—ã —Å–æ —Å–±–æ—Ä–∫–æ–π:
```bash
# –£—Å—Ç–∞–Ω–æ–≤–∫–∞ pre-built wheel
pip install https://github.com/vllm-project/vllm/releases/download/v0.8.5/vllm-0.8.5+cu118-cp310-cp310-manylinux1_x86_64.whl
```

### –®–∞–≥ 7: –£—Å—Ç–∞–Ω–æ–≤–∫–∞ flash-attention (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏)

```bash
# flash-attention –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (~500MB, 3-5 –º–∏–Ω—É—Ç)
pip install flash-attn --no-build-isolation
```

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: –ï—Å–ª–∏ —Å–±–æ—Ä–∫–∞ –ø–∞–¥–∞–µ—Ç —Å –æ—à–∏–±–∫–æ–π - –º–æ–∂–Ω–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å, vLLM –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –Ω–µ–≥–æ.

### –®–∞–≥ 8: –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–∫—Ä—É–∂–µ–Ω–∏—è

```bash
pip list | grep -E "torch|vllm|transformers|flash"
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
flash-attn              2.7.3
torch                   2.5.1+cu121
torchaudio              2.5.1+cu121
torchvision             0.20.1+cu121
transformers            4.46.3
vllm                    0.11.0
```

---

## ‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∞ DeepSeek-OCR

### –®–∞–≥ 1: –†–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ config.py

```bash
cd DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm
nano config.py
```

**–û—Å–Ω–æ–≤–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:**

```python
# –†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã (Base —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)
BASE_SIZE = 1024
IMAGE_SIZE = 1024
CROP_MODE = False  # False –¥–ª—è Base, True –¥–ª—è Gundam

# –î–ª—è —Ä–µ–∂–∏–º–∞ Base
MIN_CROPS = 1
MAX_CROPS = 1

# –î–ª—è —Ä–µ–∂–∏–º–∞ Gundam (–≥–∞–∑–µ—Ç—ã, –ø–æ—Å—Ç–µ—Ä—ã)
# CROP_MODE = True
# MIN_CROPS = 2
# MAX_CROPS = 6

# Concurrency (—É–º–µ–Ω—å—à–∏—Ç—å –µ—Å–ª–∏ –º–∞–ª–æ VRAM)
MAX_CONCURRENCY = 50  # –î–ª—è 16GB VRAM
NUM_WORKERS = 32

# –ú–æ–¥–µ–ª—å (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è —Å HuggingFace)
MODEL_PATH = 'deepseek-ai/DeepSeek-OCR'

# –ü—É—Ç–∏ –¥–ª—è —Ç–µ—Å—Ç–æ–≤
INPUT_PATH = '/mnt/c/Users/YOUR_USERNAME/Obligations/input_data/test.pdf'
OUTPUT_PATH = '/mnt/c/Users/YOUR_USERNAME/Obligations/output/result.md'

# –ü—Ä–æ–º–ø—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –¥–ª—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤)
PROMPT = '<image>\n<|grounding|>Convert the document to markdown.'
```

**–†–µ–∂–∏–º—ã DeepSeek-OCR:**

| –†–µ–∂–∏–º | BASE_SIZE | IMAGE_SIZE | CROP_MODE | Vision Tokens | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ |
|-------|-----------|------------|-----------|---------------|------------|
| **Tiny** | 512 | 512 | False | 64 | –ü—Ä–æ—Å—Ç—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã |
| **Small** | 640 | 640 | False | 100 | –°—Ä–µ–¥–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã |
| **Base** | 1024 | 1024 | False | 256 | –°—Ç–∞–Ω–¥–∞—Ä—Ç (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è) |
| **Large** | 1280 | 1280 | False | 400 | –ü–ª–æ—Ç–Ω—ã–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã |
| **Gundam** | 1024 | 640 | True | Dynamic | –ì–∞–∑–µ—Ç—ã, –ø–æ—Å—Ç–µ—Ä—ã |

### –®–∞–≥ 2: –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏)

```bash
cd DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm

# –¢–µ—Å—Ç –Ω–∞ –æ–¥–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
python run_dpsk_ocr_image.py
```

**–ü—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ:**
- –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∑–∏—Ç—Å—è —Å HuggingFace (~14GB)
- –°–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –≤ `~/.cache/huggingface/hub/`
- –ó–∞–π–º–µ—Ç 10-15 –º–∏–Ω—É—Ç

**–ì–¥–µ —Ö—Ä–∞–Ω–∏—Ç—Å—è –º–æ–¥–µ–ª—å:**
```bash
ls -lh ~/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-OCR/
```

---

## üîó –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å –ø—Ä–æ–µ–∫—Ç–æ–º

### –®–∞–≥ 1: –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞ OCR

```bash
cd /mnt/c/Users/YOUR_USERNAME/Obligations
```

–ù–∞—à –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤:
```
pdf_to_context/ocr_service/app.py
```

### –®–∞–≥ 2: –ó–∞–ø—É—Å–∫ OCR –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞

```bash
# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ DeepSeek-OCR
cd DeepSeek-OCR
source venv/bin/activate

# –ó–∞–ø—É—Å–∫–∞–µ–º FastAPI —Å–µ—Ä–≤–∏—Å (–Ω–∞—à —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π)
cd /mnt/c/Users/YOUR_USERNAME/Obligations
python -m uvicorn pdf_to_context.ocr_service.app:app --host 0.0.0.0 --port 8000
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
```bash
# –í –¥—Ä—É–≥–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ
curl http://localhost:8000/health
```

**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:**
```json
{
  "status": "healthy",
  "vllm_available": true,
  "model_loaded": true
}
```

### –®–∞–≥ 3: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ pipeline

```python
from pdf_to_context import PDFToContextPipeline

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å OCR
pipeline = PDFToContextPipeline(
    ocr_base_url="http://localhost:8000",
    prioritize_accuracy=True
)

# –û–±—Ä–∞–±–æ—Ç–∫–∞ PDF
markdown = pipeline.process(
    pdf_path="input_data/document.pdf",
    output_path="output/result.md"
)
```

---

## ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏

### –¢–µ—Å—Ç 1: PyTorch + CUDA

```bash
python3 << EOF
import torch
print(f"PyTorch: {torch.__version__}")
print(f"CUDA Available: {torch.cuda.is_available()}")
print(f"CUDA Device: {torch.cuda.get_device_name(0)}")
print(f"CUDA Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
EOF
```

### –¢–µ—Å—Ç 2: vLLM

```bash
python3 -c "import vllm; print(f'vLLM: {vllm.__version__}')"
```

### –¢–µ—Å—Ç 3: Transformers

```bash
python3 -c "from transformers import AutoTokenizer; tokenizer = AutoTokenizer.from_pretrained('deepseek-ai/DeepSeek-OCR', trust_remote_code=True); print('Tokenizer OK')"
```

### –¢–µ—Å—Ç 4: DeepSeek-OCR –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏

```bash
cd DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm

# –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º
convert -size 800x600 xc:white \
  -pointsize 48 -fill black \
  -annotate +100+300 "Test OCR Document\nLine 1\nLine 2" \
  /tmp/test_ocr.png

# –û–±–Ω–æ–≤–ª—è–µ–º config.py
python3 << EOF
import sys
sys.path.insert(0, '.')
from config import *
INPUT_PATH = '/tmp/test_ocr.png'
OUTPUT_PATH = '/tmp/test_result.md'
EOF

# –ó–∞–ø—É—Å–∫–∞–µ–º OCR
python run_dpsk_ocr_image.py
```

### –¢–µ—Å—Ç 5: –ü–æ–ª–Ω—ã–π pipeline

```bash
cd /mnt/c/Users/YOUR_USERNAME/Obligations

# –ê–∫—Ç–∏–≤–∏—Ä—É–µ–º –æ–∫—Ä—É–∂–µ–Ω–∏–µ –ø—Ä–æ–µ–∫—Ç–∞
source venv/bin/activate  # –µ—Å–ª–∏ —Å–æ–∑–¥–∞–Ω–æ –¥–ª—è –ø—Ä–æ–µ–∫—Ç–∞

# –¢–µ—Å—Ç–æ–≤—ã–π —Å–∫—Ä–∏–ø—Ç
python3 << EOF
from pdf_to_context import PDFToContextPipeline

# Health check
from pdf_to_context.extractors import OCRClient
client = OCRClient(base_url="http://localhost:8000")
print(f"OCR Service Available: {client.health_check()}")

# Pipeline test
pipeline = PDFToContextPipeline(
    ocr_base_url="http://localhost:8000",
    prioritize_accuracy=True
)
health = pipeline.health_check()
print(f"Pipeline Health: {health}")
EOF
```

### –¢–µ—Å—Ç 6: –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Å–µ—Ö –º–æ–¥—É–ª–µ–π (–†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø)

```bash
cd DeepSeek-OCR
source venv/bin/activate

# –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ (8 –º–æ–¥—É–ª–µ–π)
python check_setup.py

# –î–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å —Ç–µ—Å—Ç–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
python check_modules_detailed.py

# –ë–∞–∑–æ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –∂–∏–≤–æ—Å—Ç–∏
python test_vllm_basic.py
```

**–û–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç:**
- ‚úÖ Python Environment - PASS
- ‚úÖ PyTorch + CUDA - PASS (—Å —Ç–µ—Å—Ç–æ–º –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
- ‚úÖ PDF Libraries - PASS
- ‚úÖ Transformers - PASS (–º–æ–¥–µ–ª—å –≤ –∫—ç—à–µ)
- ‚úÖ vLLM - PASS
- ‚úÖ Web Frameworks - PASS
- ‚úÖ DeepSeek-OCR - PASS
- ‚úÖ Project Integration - PASS

---

## üêõ –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ü—Ä–æ–±–ª–µ–º–∞ 1: `nvidia-smi` –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ WSL

**–†–µ—à–µ–Ω–∏–µ:**
```bash
# –û–±–Ω–æ–≤–∏—Ç–µ –¥—Ä–∞–π–≤–µ—Ä NVIDIA –≤ Windows
# –°–∫–∞—á–∞–π—Ç–µ —Å: https://www.nvidia.com/Download/index.aspx

# –ü–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∏—Ç–µ WSL
wsl --shutdown
wsl
```

### –ü—Ä–æ–±–ª–µ–º–∞ 2: CUDA Out of Memory

**–†–µ—à–µ–Ω–∏–µ 1**: –£–º–µ–Ω—å—à–∏—Ç—å concurrency –≤ config.py
```python
MAX_CONCURRENCY = 10  # –≤–º–µ—Å—Ç–æ 100
MAX_CROPS = 2  # –≤–º–µ—Å—Ç–æ 6 –¥–ª—è Gundam
```

**–†–µ—à–µ–Ω–∏–µ 2**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ–Ω—å—à–∏–π —Ä–µ–∂–∏–º
```python
# –í–º–µ—Å—Ç–æ Base –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ Small
BASE_SIZE = 640
IMAGE_SIZE = 640
```

**–†–µ—à–µ–Ω–∏–µ 3**: –û—á–∏—Å—Ç–∏—Ç—å CUDA –∫—ç—à
```python
import torch
torch.cuda.empty_cache()
```

### –ü—Ä–æ–±–ª–µ–º–∞ 3: vLLM –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç—Å—è

**–†–µ—à–µ–Ω–∏–µ**: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å pre-built wheel
```bash
# –î–ª—è Python 3.10 + CUDA 12.1
pip install https://github.com/vllm-project/vllm/releases/download/v0.8.5/vllm-0.8.5+cu121-cp310-cp310-manylinux1_x86_64.whl
```

### –ü—Ä–æ–±–ª–µ–º–∞ 4: flash-attention —Å–±–æ—Ä–∫–∞ –ø–∞–¥–∞–µ—Ç

**–†–µ—à–µ–Ω–∏–µ**: –ü—Ä–æ–ø—É—Å—Ç–∏—Ç—å, vLLM –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –Ω–µ–≥–æ
```bash
# flash-attention –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π, –º–æ–∂–Ω–æ –Ω–µ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—Ç—å
# vLLM –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Å–≤–æ–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
```

### –ü—Ä–æ–±–ª–µ–º–∞ 5: –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–∞–µ—Ç—Å—è

**–†–µ—à–µ–Ω–∏–µ 1**: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å HuggingFace —Ç–æ–∫–µ–Ω (–¥–ª—è –ø—Ä–∏–≤–∞—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π)
```bash
huggingface-cli login
```

**–†–µ—à–µ–Ω–∏–µ 2**: –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –∏ –ø–µ—Ä–µ–∑–∞ –≥—Ä—É–∑–∏—Ç—å
```bash
rm -rf ~/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-OCR
python run_dpsk_ocr_image.py  # –ó–∞–≥—Ä—É–∑–∏—Ç—Å—è –∑–∞–Ω–æ–≤–æ
```

### –ü—Ä–æ–±–ª–µ–º–∞ 6: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è 1**: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å flash-attention
```bash
pip install flash-attn --no-build-isolation
```

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è 2**: –£–≤–µ–ª–∏—á–∏—Ç—å batch size
```python
MAX_CONCURRENCY = 100  # –µ—Å–ª–∏ —Ö–≤–∞—Ç–∞–µ—Ç VRAM
```

**–û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è 3**: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å tensor parallelism (–Ω–µ—Å–∫–æ–ª—å–∫–æ GPU)
```python
# –í –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ vLLM
tensor_parallel_size = 2  # –¥–ª—è 2 GPU
```

### –ü—Ä–æ–±–ª–µ–º–∞ 7: RTX 5080 (Blackwell, sm_120) –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å PyTorch (–ö–†–ò–¢–ò–ß–ù–û!)

**–°–∏–º–ø—Ç–æ–º:**
```
RuntimeError: CUDA error: no kernel image is available for execution on the device
NVIDIA GeForce RTX 5080 with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_37 sm_90.
```

**–ü—Ä–∏—á–∏–Ω–∞:**  
RTX 5080 –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –Ω–æ–≤–µ–π—à—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É **Blackwell (compute capability sm_120)**, –∫–æ—Ç–æ—Ä—É—é –ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç PyTorch 2.7.x –∏ —Å—Ç–∞—Ä—à–µ. PyTorch 2.7.1 —Å–æ–±—Ä–∞–Ω –ø–æ–¥ CUDA 11.8 –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–æ sm_90 (Ada Lovelace).

**‚úÖ –†–ï–®–ï–ù–ò–ï:**

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ **PyTorch 2.9.0+ —Å CUDA 12.8**:

```bash
cd ~/Obligations/DeepSeek-OCR
source venv/bin/activate

# –£–¥–∞–ª–∏—Ç—å —Å—Ç–∞—Ä—É—é –≤–µ—Ä—Å–∏—é
pip uninstall -y torch torchvision torchaudio

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å PyTorch 2.9.0 + CUDA 12.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
```bash
python3 -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'GPU: {torch.cuda.get_device_name(0)}'); print(f'CUDA Available: {torch.cuda.is_available()}')"
```

**–û–∂–∏–¥–∞–µ–º—ã–π –≤—ã–≤–æ–¥:**
```
PyTorch: 2.9.0+cu128
GPU: NVIDIA GeForce RTX 5080
CUDA Available: True
```

**–°–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å:**
- ‚úÖ PyTorch 2.9.0+: –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç sm_120 (Blackwell)
- ‚úÖ PyTorch 2.8.0+: —á–∞—Å—Ç–∏—á–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ Blackwell
- ‚ùå PyTorch 2.7.x –∏ —Å—Ç–∞—Ä—à–µ: –ù–ï –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç sm_120

### –ü—Ä–æ–±–ª–µ–º–∞ 8: –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å vLLM (—É—Å—Ç–∞—Ä–µ–ª–æ - –±–æ–ª—å—à–µ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º)

**–í–ê–ñ–ù–û:** –ú—ã **–æ—Ç–∫–∞–∑–∞–ª–∏—Å—å –æ—Ç vLLM** –∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º **HuggingFace Transformers API** –Ω–∞–ø—Ä—è–º—É—é.

**–ü—Ä–∏—á–∏–Ω–∞ –æ—Ç–∫–∞–∑–∞:**
- –°–ª–æ–∂–Ω—ã–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏ —á–∞—Å—Ç—ã–µ breaking changes –≤ vLLM
- –ü—Ä–æ–±–ª–µ–º—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å –Ω–æ–≤–µ–π—à–∏–º–∏ GPU (RTX 5080)
- –ò–∑–±—ã—Ç–æ—á–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è –Ω–∞—à–µ–≥–æ use-case

**‚úÖ –¢–ï–ö–£–©–ï–ï –†–ï–®–ï–ù–ò–ï:**

–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ **–Ω–∞—à FastAPI –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å —Å HuggingFace API**:

```bash
# –ó–∞–ø—É—Å–∫ OCR –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–∞ (–±–µ–∑ vLLM!)
cd ~/Obligations
source DeepSeek-OCR/venv/bin/activate
python -m uvicorn pdf_to_context.ocr_service.app:app --host 0.0.0.0 --port 8000
```

**–ü—Ä–æ–≤–µ—Ä–∫–∞:**
```bash
curl http://localhost:8000/health
```

**–û–∂–∏–¥–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç:**
```json
{
  "status": "healthy",
  "model_loaded": true,
  "cuda_available": true,
  "cuda_device": "NVIDIA GeForce RTX 5080"
}
```

**–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –Ω–∞—à–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∞:**
- ‚úÖ –ü—Ä–æ—Å—Ç–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ (—Ç–æ–ª—å–∫–æ transformers + PyTorch)
- ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç —Å RTX 5080 –∏ PyTorch 2.9.0
- ‚úÖ HTTP API –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏
- ‚úÖ –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
- ‚úÖ –ë–µ–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç vLLM

---

## üì¶ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è –¥–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏

### –ß—Ç–æ –ù–ï –∫–æ–º–∏—Ç–∏—Ç—å –≤ git

–î–æ–±–∞–≤—å—Ç–µ –≤ `.gitignore`:
```
# DeepSeek-OCR
DeepSeek-OCR/venv/
DeepSeek-OCR/venv_deepseek/
DeepSeek-OCR/__pycache__/
DeepSeek-OCR/**/__pycache__/
DeepSeek-OCR/**/*.pyc

# HuggingFace cache (–º–æ–¥–µ–ª–∏)
.cache/

# venv –ø—Ä–æ–µ–∫—Ç–∞
venv/
venv_*/

# Output
output/
*.md.bak
```

### –ß—Ç–æ –∫–æ–º–∏—Ç–∏—Ç—å

- ‚úÖ `DeepSeek-OCR/DeepSeek-OCR-master/DeepSeek-OCR-vllm/config.py` (–Ω–∞—Å—Ç—Ä–æ–π–∫–∏)
- ‚úÖ `pdf_to_context/ocr_service/app.py` (–Ω–∞—à –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å)
- ‚úÖ `docs/DeepSeek_OCR_Setup.md` (—ç—Ç–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è)
- ‚úÖ `requirements.txt` (–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –ø—Ä–æ–µ–∫—Ç–∞)

### –ë—ã—Å—Ç—Ä–∞—è —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –Ω–∞ –≤—Ç–æ—Ä–æ–º –∫–æ–º–ø—å—é—Ç–µ—Ä–µ

```bash
# 1. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
git clone YOUR_REPO_URL Obligations
cd Obligations

# 2. –ö–ª–æ–Ω–∏—Ä–æ–≤–∞—Ç—å DeepSeek-OCR
git clone https://github.com/deepseek-ai/DeepSeek-OCR.git
cd DeepSeek-OCR

# 3. –°–æ–∑–¥–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ –∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –≤—Å–µ (–∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è 15-20 –º–∏–Ω—É—Ç)
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
pip install vllm
pip install flash-attn --no-build-isolation

# 4. –ü—Ä–æ–≤–µ—Ä–∫–∞
python3 -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"

# 5. –ü–µ—Ä–≤—ã–π –∑–∞–ø—É—Å–∫ (–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ 10-15 –º–∏–Ω—É—Ç)
cd DeepSeek-OCR-master/DeepSeek-OCR-vllm
python run_dpsk_ocr_image.py
```

---

## üìù –ü–æ–ª–µ–∑–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ WSL

```powershell
# –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å WSL
wsl --shutdown

# –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤
wsl --distribution Ubuntu-22.04

# –°–ø–∏—Å–æ–∫ –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤–æ–≤
wsl --list --verbose

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
wsl --set-default Ubuntu-22.04
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU

```bash
# –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
watch -n 1 nvidia-smi

# –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ª—å–∫–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
nvidia-smi --query-gpu=memory.used,memory.total --format=csv

# –õ–æ–≥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU
nvidia-smi dmon -s u
```

### –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è–º–∏

```bash
# –ê–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ DeepSeek-OCR
cd DeepSeek-OCR && source venv/bin/activate

# –î–µ–∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å
deactivate

# –£–¥–∞–ª–∏—Ç—å –æ–∫—Ä—É–∂–µ–Ω–∏–µ (–µ—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å)
rm -rf venv
python3 -m venv venv
```

### –û—á–∏—Å—Ç–∫–∞ –∫—ç—à–∞ –∏ –º–µ—Å—Ç–∞

```bash
# –û—á–∏—Å—Ç–∫–∞ pip –∫—ç—à–∞
pip cache purge

# –û—á–∏—Å—Ç–∫–∞ HuggingFace –∫—ç—à–∞ (–æ—Å–≤–æ–±–æ–¥–∏—Ç ~14GB)
rm -rf ~/.cache/huggingface/

# –û—á–∏—Å—Ç–∫–∞ PyTorch –∫—ç—à–∞
rm -rf ~/.cache/torch/

# –ü–æ–∫–∞–∑–∞—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –º–µ—Å—Ç–∞
du -sh ~/.cache/*
```

---

## üöÄ –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å

### –û–∂–∏–¥–∞–µ–º–∞—è —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫–∏

**GPU: RTX 5080 (16GB VRAM)**

| –†–µ–∂–∏–º | –°—Ç—Ä–∞–Ω–∏—Ü–∞ (–ø—Ä–æ—Å—Ç–∞—è) | –°—Ç—Ä–∞–Ω–∏—Ü–∞ (—Å–ª–æ–∂–Ω–∞—è) | –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ |
|-------|-------------------|-------------------|-------------|
| Tiny | ~0.5 —Å–µ–∫ | ~1 —Å–µ–∫ | ~0.3 —Å–µ–∫ |
| Small | ~0.8 —Å–µ–∫ | ~1.5 —Å–µ–∫ | ~0.5 —Å–µ–∫ |
| **Base** | **~1.5 —Å–µ–∫** | **~3 —Å–µ–∫** | **~1 —Å–µ–∫** |
| Large | ~3 —Å–µ–∫ | ~6 —Å–µ–∫ | ~2 —Å–µ–∫ |
| Gundam | ~5-10 —Å–µ–∫ | ~10-20 —Å–µ–∫ | - |

**Batch processing:**
- Single page: 1-3 —Å–µ–∫
- 10 pages: 15-30 —Å–µ–∫
- 100 pages: 2-5 –º–∏–Ω—É—Ç

---

## üìö –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ä–µ—Å—É—Ä—Å—ã

- [DeepSeek-OCR GitHub](https://github.com/deepseek-ai/DeepSeek-OCR)
- [vLLM Documentation](https://docs.vllm.ai/)
- [CUDA WSL Guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)
- [PyTorch Installation](https://pytorch.org/get-started/locally/)

---

## ‚úâÔ∏è –ü–æ–¥–¥–µ—Ä–∂–∫–∞

–ü—Ä–∏ –ø—Ä–æ–±–ª–µ–º–∞—Ö –ø—Ä–æ–≤–µ—Ä—å—Ç–µ:
1. ‚úÖ NVIDIA –¥—Ä–∞–π–≤–µ—Ä –æ–±–Ω–æ–≤–ª–µ–Ω –≤ Windows
2. ‚úÖ WSL2 (–Ω–µ WSL1)
3. ‚úÖ `nvidia-smi` —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ WSL
4. ‚úÖ PyTorch –≤–∏–¥–∏—Ç CUDA (`torch.cuda.is_available()`)
5. ‚úÖ –î–æ—Å—Ç–∞—Ç–æ—á–Ω–æ VRAM (–º–∏–Ω–∏–º—É–º 8GB)

–ï—Å–ª–∏ –ø—Ä–æ–±–ª–µ–º—ã –æ—Å—Ç–∞–ª–∏—Å—å - —Å–º. —Ä–∞–∑–¥–µ–ª [–†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º](#—Ä–µ—à–µ–Ω–∏–µ-–ø—Ä–æ–±–ª–µ–º).

